# -*- coding: utf-8 -*-
"""DS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OeBX9Vj-w4R021KfgQPiZQmFFBtvAjTi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')

import nltk

"""#to run the data
df = pd.read_csv('./Reviews.csv')
print(df.shape)
df = df.head(400)
print(df.shape)

ParserError                               Traceback (most recent call last)
"""

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv("/content/drive/MyDrive/Files/review ds dataset /Reviews.csv")

print(df.shape)

df = df.head(800)
print(df.shape)

df.head()

df.tail()

ax = df['Score'].value_counts()
ax

"""if to see the certain review of value

use:
df['Text'].values[0]
"""

ax = df['Score'].value_counts().sort_index() \
    .plot(kind='bar',
          title='Count of Reviews by Stars',
          figsize=(10, 5))
ax.set_xlabel('Review Stars')
plt.show()

example = df['Text'][500]
print(example)

import nltk
nltk.download('punkt')

tokens = nltk.word_tokenize(example)
tokens[:12]

"""download 'punkt'
for word_tokenize and other functions
"""

nltk.word_tokenize(example)

!pip install nltk
import nltk
nltk.download('averaged_perceptron_tagger')

tagged = nltk.pos_tag(tokens)
tagged[:10]

nltk.download('maxent_ne_chunker')
nltk.download('words')

entities = nltk.chunk.ne_chunk(tagged)
entities.pprint()

entities = nltk.chunk.ne_chunk(tagged)
entities.pprint()

"""**vader**
for pos,neg,nue
in nltk **SentimentIntensityAnalyzer**
"""

nltk.download('vader_lexicon')

from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

sia = SentimentIntensityAnalyzer()

sia

sia.polarity_scores('i am so happy!')

sia.polarity_scores('i am so sad!')

sia.polarity_scores(example)

"""to run in every **review ** can make a loop tqdm"""

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    text = row['Text']
    myid = row['Id']
    res[myid] = sia.polarity_scores(text)

res

"""store in pandas data frame"""

pd.DataFrame(res)

""".T to transpose"""

pd.DataFrame(res).T

"""renaming the column as id"""

vaders = pd.DataFrame(res).T
vaders = vaders.reset_index().rename(columns={'index': 'Id'})
vaders = vaders.merge(df, how='left')

vaders

ax = sns.barplot(data=vaders, x='Score', y='compound')
ax.set_title('Compund Score')
plt.show()

fig, axs = plt.subplots(1, 3, figsize=(12, 3))
sns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])
sns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])
sns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])
axs[0].set_title('Positive')
axs[1].set_title('Neutral')
axs[2].set_title('Negative')
plt.tight_layout()
plt.show()

"""roberta"""

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

print(example)
sia.polarity_scores(example)

"""this id the previous example oh vader which is seen above

***encoded*** value of **vaders**
for understand to the model
"""

tokenizer(example,return_tensors='pt')

encoded_text = tokenizer(example, return_tensors='pt')
output = model(**encoded_text)
scores = output[0][0].detach().numpy()
scores = softmax(scores)
scores_dict = {
    'roberta_neg' : scores[0],
    'roberta_neu' : scores[1],
    'roberta_pos' : scores[2]
}
print(scores_dict)

def polarity_scores_roberta(example):
    encoded_text = tokenizer(example, return_tensors='pt')
    output = model(**encoded_text)
    scores = output[0][0].detach().numpy()
    scores = softmax(scores)
    scores_dict = {
        'roberta_neg' : scores[0],
        'roberta_neu' : scores[1],
        'roberta_pos' : scores[2]
    }
    return scores_dict

"""disadvantages of roberta
     long text review is unable to pr
"""

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
        text = row['Text']
        myid = row['Id']
        vader_result = sia.polarity_scores(text)
        vader_result_rename = {}
        for key, value in vader_result.items():
            vader_result_rename[f"vader_{key}"] = value
        roberta_result = polarity_scores_roberta(text)
        both = {**vader_result_rename, **roberta_result}
        res[myid] = both

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    try:
        text = row['Text']
        myid = row['Id']
        vader_result = sia.polarity_scores(text)
        vader_result_rename = {}
        for key, value in vader_result.items():
            vader_result_rename[f"vader_{key}"] = value
        roberta_result = polarity_scores_roberta(text)
        both = {**vader_result_rename, **roberta_result}
        res[myid] = both
    except RuntimeError:
        print(f'Broke for id {myid}')

"""required some time for the roberta model for alalise the review"""

results_df = pd.DataFrame(res).T
results_df = results_df.reset_index().rename(columns={'index': 'Id'})
results_df = results_df.merge(df, how='left')

results_df

results_df.columns

"""vewing the low star rating with possitive review in the dataset"""

results_df.query('Score == 1') \
    .sort_values('roberta_pos', ascending=False)['Text'].values[0]

results_df.query('Score == 1') \
    .sort_values('vader_pos', ascending=False)['Text'].values[0]

"""lets see the 5 star rating with negative command"""

results_df.query('Score == 5') \
    .sort_values('roberta_neg', ascending=False)['Text'].values[0]

results_df.query('Score == 5') \
    .sort_values('vader_neg', ascending=False)['Text'].values[0]

"""now pipeline is automatically downlode the default model of the sentimental analysis and can run the code in 2 lines

from transformers import pipeline

sent_pipeline = pipeline("sentiment-analysis")

sent_pipeline('I love sentiment analysis!')
sent_pipeline('Make sure to like')
sent_pipeline('sad')
"""

results_df.query('Score == 3') \
    .sort_values('vader_neg', ascending=False)['Text'].values[0]

results_df.query('Score == 3') \
    .sort_values('roberta_neg', ascending=False)['Text'].values[0]

exm = df['Text'][560]
print(example)

"""create using pipeline"""

from transformers import pipeline

sent_pipeline = pipeline("sentiment-analysis")

sent_pipeline('I love sentiment analysis!')

mean_values = vaders[['pos', 'neu', 'neg']].mean()
mean_values

colors = sns.color_palette('pastel')[0:3]
labels=['Positive', 'Neutral', 'Negative']
#create pie chart
plt.pie(mean_values, labels = labels, colors = colors, autopct='%1.1f%%')
plt.show()

sns.pairplot(data=results_df,
             vars=['vader_neg', 'vader_neu', 'vader_pos',
                  'roberta_neg', 'roberta_neu', 'roberta_pos'],
            hue='Score',
            palette='tab10')
plt.show()

results_df.query('Score == 3') \
    .sort_values('vader_neg', ascending=False)['Text'].values[0]

results_df.query('Score == 5') \
    .sort_values('roberta_neg', ascending=False)['Text'].values[0]

sent_pipeline('I am so happy!')

sent_pipeline('I am sad!')